---
outline: deep
---

# 并发其他知识点

## 用户空间与内核空间

内核空间是操作系统内核代码运行使用的内存空间，可以调用系统的一切资源，比如读写磁盘文件、分配回收内存、从网络接口读写数据等等。

用户空间是用户程序运行使用的内存空间，用户空间的程序不能直接调用系统资源，必须通过系统层面API去调用内核空间的系统程序来完成资源操作。

## IO模型

### 同步阻塞IO

BIO中，应用程序如JVM，从发起IO系统调用开始，直到IO系统调用返回，一直处于阻塞状态。等到系统调用将数据拷贝到用户空间后，应用程序才开始处理数据。
线程由于IO陷入阻塞，指的就是这里的BIO阻塞。

> 注意这里说的阻塞不是JVM线程的BLOCKED状态。

### 同步非阻塞IO

同步非阻塞IO中，应用程序发起的IO系统调用会有两种情况：

- 内核空间还没有完成"从硬件设备拷贝目标数据到内核空间"，则立即返回调用失败，应用程序可以不断重复尝试；
- 内核空间已经完成"拷贝目标数据到内核空间"
  ，则开始拷贝内核空间的数据到用户空间，此时应用程序处于阻塞状态，但从内核空间拷贝到用户空间都是内存内部操作，比起从硬件设备读取要快得多，所以这个阻塞时间已经很小了。

NIO模型中每次发起IO系统调用，如果内核空间缓存数据尚未就绪，应用程序的对应线程不会被阻塞，而是不停轮询，因此单次读写的实时性会比较好。但就像CAS自旋一样，这种轮询操作是要占用CPU的，在性能上是一种极大的浪费，会严重影响系统整体的吞吐量。因此事实上NIO模型基本上没有哪种语言或框架使用，更多被使用的是BIO或者接下来要说的IO多路复用。

### IO多路复用

无论是BIO还是NIO，都需要应用程序为每个磁盘文件或网络连接创建一个线程，而不管这个线程是阻塞的还是一直傻乎乎地轮询，都会占用操作系统宝贵的线程资源或CPU。
因此，操作系统又提供了IO多路复用模型。其思路是只用一个线程不断轮询数据是否就绪，等就绪了再调度其他线程来读写。

### 异步非阻塞IO

AIO的基本流程是，应用程序通过特殊的IO系统调用，向内核注册一个IO操作，内核在整个IO完成后通知应用程序。
这里说的整个IO，包括内核空间的数据就绪，也包括内核空间与用户空间之间的数据拷贝。

## 并发问题的解决方案

### 什么是多线程模型

多线程，顾名思义就是多开线程让它们并发执行，最好能并行执行，以达到更快完成任务的目的。
但由于线程执行过程当中难免遇到IO，IO不需要CPU，但是会让线程进入阻塞的状态，比如磁盘读写。
如果线程陷入IO阻塞而CPU没有其他线程去调用，就会浪费CPU。
多线程模型减少CPU浪费的方法很简单粗暴，就是增加线程数量。这样当一个线程被IO阻塞时，CPU就可以选择其他线程去运行。
但多个线程都要访问同一个状态，即共享变量时，会产生线程不安全的问题。而为了保证线程安全，它又提供了锁机制做同步。

### 多线程模型的问题

假如有一个生产手工艺品的工厂，目前是每个工人(线程)
从头到尾独自打造手工艺品，现在产能不足，用多线程模型，就是简单粗暴地多招一些工人(增加线程)，想让他们并行地去各自打造手工艺品。
但是这个过程中，每个工人的生产过程会受到生产资料的限制。比如工人太多了，某些工具不够，于是要排队等着用工具，这就是对共享变量的锁机制会导致线程阻塞。
比如工厂的车间只有100个工位(CPU)
，那你招更多的工人也只能保证同时只有100个工人在干活。当某个工人的制作流程到了某个环节需要某种生产原材料，要等采购，这个工人就只能等着(
Future.get()阻塞当前线程)，于是工人就要让出工位(CPU切换线程)，工人越多，管理越复杂，工人换工位要处理的事情就越多，这就是线程太多导致的线程切换的高额成本。

> 所以，多线程模型就是通过增加线程(工人)的方式来压榨CPU(工位)
> 使其一直运转不浪费的模型。但在此过程中，工人雇佣太多也会浪费并提高成本(线程不能开太多,线程切换开销很大)。

多线程模型理解起来很简单，但实际开发的时候会遇到两个比较难以解决的问题：

锁机制开发繁杂易错，且是性能瓶颈。
多线程模型中，对共享变量的上锁机制不但使用起来比较繁杂，容易出错，还会成为整个任务执行的瓶颈，因为被上锁的操作是排他互斥的，不能并行执行。尽管Java的synchronized和JUC的锁都做出了很多改善，但实话实说，多线程开发仍然是大部分Java开发人员并不真正掌握的高阶技能。

多线程模型这样简单粗暴地试图通过增加线程数量来压榨CPU性能的做法也很容易受到CPU核数的限制，较少的CPU在较多的内核线程之间频繁切换是对CPU性能的浪费，其吞吐量并不能满足当下的高并发需求。

### 线程数量与性能表现

线程数量太多时，反而会降低性能。

- 创建线程开销较大
- 线程上下文切换，当线程数量超过CPU核数时，CPU需要在不同的线程上轮转调用
- CPU缓存命中率下降，多线程访问共享变量时，会将共享变量拷贝一份到CPU的高速缓存(即JMM的主存与工作内存)
  ，频繁的线程切换会导致大量的CPU高速缓存失效
- 资源抢占会引起其他线程阻塞，甚至有可能造成死锁。

### 线程池的线程数量

对于IO密集型，要根据CPU核数和IO目标来确定，理论指导值是CPU核数×2+IO设备数。线程数首先取决于CPU核数很好理解，因为每个线程运行都需要占用一颗CPU
Core。乘以2，是因为目前的CPU通常都具备超线程技术，1颗CPU可以同时执行两个进程。当然，即使没有超线程技术，也常常乘以2，这是为了更好地压榨CPU性能。还要加上IO设备数，是因为线程读写磁盘或者网络连接时是阻塞的，CPU此时可以去调度其他线程。

对于CPU密集型，理论上应该等于CPU核数，但在实际业务场景中，所谓CPU密集型也只是IO密度比较低而已，总是不可避免会出现一些非常短暂的线程阻塞，所以可能把线程数调大点效果会更好，更能压榨CPU性能。

在多线程编程中，实际线程数与理论线程数之间存在差异的两个关键因素是：

1. 其他任务对CPU资源的抢夺：在同一时间段内，其他任务可能会竞争CPU资源，导致线程无法按照理论上的预期运行。这种竞争会影响线程的执行效率和速度。
2. 任务单次耗时的稳定性：某些任务的单次执行时间可能会有波动，无法保证稳定性。这种波动会导致线程在不同运行时段表现出不同的性能，使得实际线程数与理论线程数之间存在较大差异。

生产环境中应该想办法把这种多线程的线程数设置为可以动态调整的属性，通过不断的尝试，找到当下比较合适的线程数。
